@ARTICLE{8526323, 
author={J. {Dass} and V. {Sarin} and R. N. {Mahapatra}}, 
journal={IEEE Transactions on Parallel and Distributed Systems}, 
title={Fast and Communication-Efficient Algorithm for Distributed Support Vector Machine Training}, 
year={2019}, 
volume={30}, 
number={5}, 
pages={1065-1076}, 
keywords={learning (artificial intelligence);matrix algebra;multiprocessing systems;pattern classification;support vector machines;supervised learning models;classification problem;machine learning;computational requirements;big data problems;scalable distributed algorithms;model training;distributed algorithm;SVM training;low-rank approximations;storage requirements;training stage;benchmark data sets;communication-efficient algorithm;distributed support vector machine training;computation requirements;QR decomposition;kernel matrix;Support vector machines;Kernel;Training;Matrix decomposition;Optimization;Benchmark testing;Convergence;Machine learning;support vector machines;classification algorithms;parallel programming;distributed computing;message passing;quadratic programming;iterative algorithms;optimization;multicore processing}, 
doi={10.1109/TPDS.2018.2879950}, 
ISSN={1045-9219}, 
month={May},
}
